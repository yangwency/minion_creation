{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "os — Miscellaneous operating system interfaces, this module provides a portable way of using operating system dependent functionality.\n",
    "\n",
    "The pickle module implements binary protocols for serializing and de-serializing a Python object structure. “Pickling” is the process whereby a Python object hierarchy is converted into a byte stream, and “unpickling” is the inverse operation, whereby a byte stream (from a [binary file](https://docs.python.org/3/glossary.html#term-binary-file) or [bytes-like object](https://docs.python.org/3/glossary.html#term-bytes-like-object)) is converted back into an object hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from . import dft\n",
    "from .utils import download_and_extract_tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a pipefile from a list of image files.\n",
    "    Includes batch generator/central crop/resizing options.\n",
    "    The resulting generator will dequeue the images batch_size at a time until\n",
    "    it throws tf.errors.OutOfRangeError when there are no more images left in\n",
    "    the queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_pipeline(files, batch_size, n_epochs, shape, crop_shape=None,\n",
    "                          crop_factor=1.0, n_threads=4):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    files : list\n",
    "        List of paths to image files.\n",
    "    batch_size : int\n",
    "        Number of image files to load at a time.\n",
    "    n_epochs : int\n",
    "        Number of epochs to run before raising tf.errors.OutOfRangeError\n",
    "    shape : list\n",
    "        [height, width, channels]\n",
    "    crop_shape : list\n",
    "        [height, width] to crop image to.\n",
    "    crop_factor : float\n",
    "        Percentage of image to take starting from center.\n",
    "    n_threads : int, optional\n",
    "        Number of threads to use for batch shuffling\n",
    "    \"\"\"\n",
    "\n",
    "    # We first create a \"producer\" queue.  It creates a production line which\n",
    "    # will queue up the file names and allow another queue to deque the file\n",
    "    # names all using a tf queue runner.\n",
    "    # Put simply, this is the entry point of the computational graph.\n",
    "    # It will generate the list of file names.\n",
    "    # We also specify it's capacity beforehand.\n",
    "    producer = tf.train.string_input_producer(\n",
    "        files, capacity=len(files))\n",
    "\n",
    "    # We need something which can open the files and read its contents.\n",
    "    reader = tf.WholeFileReader()\n",
    "\n",
    "    # We pass the filenames to this object which can read the file's contents.\n",
    "    # This will create another queue running which dequeues the previous queue.\n",
    "    keys, vals = reader.read(producer)\n",
    "\n",
    "    # And then have to decode its contents as we know it is a jpeg image\n",
    "    imgs = tf.image.decode_jpeg(\n",
    "        vals,\n",
    "        channels=3 if len(shape) > 2 and shape[2] == 3 else 0)\n",
    "\n",
    "    # We have to explicitly define the shape of the tensor.\n",
    "    # This is because the decode_jpeg operation is still a node in the graph\n",
    "    # and doesn't yet know the shape of the image.  Future operations however\n",
    "    # need explicit knowledge of the image's shape in order to be created.\n",
    "    imgs.set_shape(shape)\n",
    "\n",
    "    # Next we'll centrally crop the image to the size of 100x100.\n",
    "    # This operation required explicit knowledge of the image's shape.\n",
    "    if shape[0] > shape[1]:\n",
    "        rsz_shape = [int(shape[0] / shape[1] * crop_shape[0] / crop_factor),\n",
    "                     int(crop_shape[1] / crop_factor)]\n",
    "    else:\n",
    "        rsz_shape = [int(crop_shape[0] / crop_factor),\n",
    "                     int(shape[1] / shape[0] * crop_shape[1] / crop_factor)]\n",
    "    rszs = tf.image.resize_images(imgs, rsz_shape)\n",
    "    crops = (tf.image.resize_image_with_crop_or_pad(\n",
    "        rszs, crop_shape[0], crop_shape[1])\n",
    "        if crop_shape is not None\n",
    "        else imgs)\n",
    "\n",
    "    # Now we'll create a batch generator that will also shuffle our examples.\n",
    "    # We tell it how many it should have in its buffer when it randomly\n",
    "    # permutes the order.\n",
    "    min_after_dequeue = len(files) // 10\n",
    "\n",
    "    # The capacity should be larger than min_after_dequeue, and determines how\n",
    "    # many examples are prefetched.  TF docs recommend setting this value to:\n",
    "    # min_after_dequeue + (num_threads + a small safety margin) * batch_size\n",
    "    capacity = min_after_dequeue + (n_threads + 1) * batch_size\n",
    "\n",
    "    # Randomize the order and output batches of batch_size.\n",
    "    batch = tf.train.shuffle_batch([crops],\n",
    "                                   enqueue_many=False,\n",
    "                                   batch_size=batch_size,\n",
    "                                   capacity=capacity,\n",
    "                                   min_after_dequeue=min_after_dequeue,\n",
    "                                   num_threads=n_threads)\n",
    "\n",
    "    # alternatively, we could use shuffle_batch_join to use multiple reader\n",
    "    # instances, or set shuffle_batch's n_threads to higher than 1.\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the GTZAN music and speech dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gtzan_music_speech_download(dst='gtzan_music_speech'):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    dst : str, optional\n",
    "        Location to put the GTZAN music and speech datset.\n",
    "    \"\"\"\n",
    "    path = 'http://opihi.cs.uvic.ca/sound/music_speech.tar.gz'\n",
    "    download_and_extract_tar(path, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the GTZAN Music and Speech dataset.\n",
    "    Downloads the dataset if it does not exist into the dst directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gtzan_music_speech_load(dst='gtzan_music_speech'):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    dst : str, optional\n",
    "        Location of GTZAN Music and Speech dataset.\n",
    "    Returns\n",
    "    -------\n",
    "    Xs, ys : np.ndarray, np.ndarray\n",
    "        Array of data, Array of labels\n",
    "    \"\"\"\n",
    "    from scipy.io import wavfile\n",
    "\n",
    "    if not os.path.exists(dst):\n",
    "        gtzan_music_speech_download(dst)\n",
    "    music_dir = os.path.join(os.path.join(dst, 'music_speech'), 'music_wav')\n",
    "    music = [os.path.join(music_dir, file_i)\n",
    "             for file_i in os.listdir(music_dir)\n",
    "             if file_i.endswith('.wav')]\n",
    "    speech_dir = os.path.join(os.path.join(dst, 'music_speech'), 'speech_wav')\n",
    "    speech = [os.path.join(speech_dir, file_i)\n",
    "              for file_i in os.listdir(speech_dir)\n",
    "              if file_i.endswith('.wav')]\n",
    "    Xs = []\n",
    "    ys = []\n",
    "    for i in music:\n",
    "        sr, s = wavfile.read(i)\n",
    "        s = s / 16384.0 - 1.0\n",
    "        re, im = dft.dft_np(s)\n",
    "        mag, phs = dft.ztoc(re, im)\n",
    "        Xs.append((mag, phs))\n",
    "        ys.append(0)\n",
    "    for i in speech:\n",
    "        sr, s = wavfile.read(i)\n",
    "        s = s / 16384.0 - 1.0\n",
    "        re, im = dft.dft_np(s)\n",
    "        mag, phs = dft.ztoc(re, im)\n",
    "        Xs.append((mag, phs))\n",
    "        ys.append(1)\n",
    "    Xs = np.array(Xs)\n",
    "    Xs = np.transpose(Xs, [0, 2, 3, 1])\n",
    "    ys = np.array(ys)\n",
    "    return Xs, ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cifar10_download(dst='cifar10'):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    dst : str, optional\n",
    "        Directory to download into.\n",
    "    \"\"\"\n",
    "    path = 'http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
    "    download_and_extract_tar(path, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the CIFAR10 dataset.\n",
    "    Downloads the dataset if it does not exist into the dst directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cifar10_load(dst='cifar10'):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    dst : str, optional\n",
    "        Location of CIFAR10 dataset.\n",
    "    Returns\n",
    "    -------\n",
    "    Xs, ys : np.ndarray, np.ndarray\n",
    "        Array of data, Array of labels\n",
    "    \"\"\"\n",
    "    if not os.path.exists(dst):\n",
    "        cifar10_download(dst)\n",
    "    Xs = None\n",
    "    ys = None\n",
    "    for f in range(1, 6):\n",
    "        cf = pickle.load(open(\n",
    "            '%s/cifar-10-batches-py/data_batch_%d' % (dst, f), 'rb'),\n",
    "            encoding='LATIN')\n",
    "        if Xs is not None:\n",
    "            Xs = np.r_[Xs, cf['data']]\n",
    "            ys = np.r_[ys, np.array(cf['labels'])]\n",
    "        else:\n",
    "            Xs = cf['data']\n",
    "            ys = cf['labels']\n",
    "    Xs = np.swapaxes(np.swapaxes(Xs.reshape(-1, 3, 32, 32), 1, 3), 1, 2)\n",
    "    return Xs, ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert class labels from scalars to one-hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_to_one_hot(labels, n_classes=2):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    labels : array\n",
    "        Input labels to convert to one-hot representation.\n",
    "    n_classes : int, optional\n",
    "        Number of possible one-hot.\n",
    "    Returns\n",
    "    -------\n",
    "    one_hot : array\n",
    "        One hot representation of input.\n",
    "    \"\"\"\n",
    "    return np.eye(n_classes).astype(np.float32)[labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility class for batching data and handling multiple splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetSplit(object):\n",
    "    \"\"\"\n",
    "    Attributes\n",
    "    ----------\n",
    "    current_batch_idx : int\n",
    "        Description\n",
    "    images : np.ndarray\n",
    "        Xs of the dataset.  Not necessarily images.\n",
    "    labels : np.ndarray\n",
    "        ys of the dataset.\n",
    "    n_labels : int\n",
    "        Number of possible labels\n",
    "    num_examples : int\n",
    "        Number of total observations\n",
    "    \"\"\"\n",
    "    def __init__(self, images, labels):\n",
    "        \"\"\"Initialize a DatasetSplit object.\n",
    "        Parameters\n",
    "        ----------\n",
    "        images : np.ndarray\n",
    "            Xs/inputs\n",
    "        labels : np.ndarray\n",
    "            ys/outputs\n",
    "        \"\"\"\n",
    "        self.images = np.array(images).astype(np.float32)\n",
    "        if labels is not None:\n",
    "            self.labels = np.array(labels).astype(np.int32)\n",
    "            self.n_labels = len(np.unique(labels))\n",
    "        else:\n",
    "            self.labels = None\n",
    "        self.num_examples = len(self.images)\n",
    "\n",
    "    def next_batch(self, batch_size=100):\n",
    "        \"\"\"Batch generator with randomization.\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_size : int, optional\n",
    "            Size of each minibatch.\n",
    "        Returns\n",
    "        -------\n",
    "        Xs, ys : np.ndarray, np.ndarray\n",
    "            Next batch of inputs and labels (if no labels, then None).\n",
    "        \"\"\"\n",
    "        # Shuffle each epoch\n",
    "        current_permutation = np.random.permutation(range(len(self.images)))\n",
    "        epoch_images = self.images[current_permutation, ...]\n",
    "        if self.labels is not None:\n",
    "            epoch_labels = self.labels[current_permutation, ...]\n",
    "\n",
    "        # Then iterate over the epoch\n",
    "        self.current_batch_idx = 0\n",
    "        while self.current_batch_idx < len(self.images):\n",
    "            end_idx = min(\n",
    "                self.current_batch_idx + batch_size, len(self.images))\n",
    "            this_batch = {\n",
    "                'images': epoch_images[self.current_batch_idx:end_idx],\n",
    "                'labels': epoch_labels[self.current_batch_idx:end_idx]\n",
    "                if self.labels is not None else None\n",
    "            }\n",
    "            self.current_batch_idx += batch_size\n",
    "            yield this_batch['images'], this_batch['labels']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataset from data and their labels.\n",
    "    Allows easy use of train/valid/test splits; Batch generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    \"\"\"\n",
    "    Attributes\n",
    "    ----------\n",
    "    all_idxs : list\n",
    "        All indexes across all splits.\n",
    "    all_inputs : list\n",
    "        All inputs across all splits.\n",
    "    all_labels : list\n",
    "        All labels across all splits.\n",
    "    n_labels : int\n",
    "        Number of labels.\n",
    "    split : list\n",
    "        Percentage split of train, valid, test sets.\n",
    "    test_idxs : list\n",
    "        Indexes of the test split.\n",
    "    train_idxs : list\n",
    "        Indexes of the train split.\n",
    "    valid_idxs : list\n",
    "        Indexes of the valid split.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, Xs, ys=None, split=[1.0, 0.0, 0.0], one_hot=False):\n",
    "        \"\"\"Initialize a Dataset object.\n",
    "        Parameters\n",
    "        ----------\n",
    "        Xs : np.ndarray\n",
    "            Images/inputs to a network\n",
    "        ys : np.ndarray\n",
    "            Labels/outputs to a network\n",
    "        split : list, optional\n",
    "            Percentage of train, valid, and test sets.\n",
    "        one_hot : bool, optional\n",
    "            Whether or not to use one-hot encoding of labels (ys).\n",
    "        \"\"\"\n",
    "        self.all_idxs = []\n",
    "        self.all_labels = []\n",
    "        self.all_inputs = []\n",
    "        self.train_idxs = []\n",
    "        self.valid_idxs = []\n",
    "        self.test_idxs = []\n",
    "        self.n_labels = 0\n",
    "        self.split = split\n",
    "\n",
    "        # Now mix all the labels that are currently stored as blocks\n",
    "        self.all_inputs = Xs\n",
    "        n_idxs = len(self.all_inputs)\n",
    "        idxs = range(n_idxs)\n",
    "        rand_idxs = np.random.permutation(idxs)\n",
    "        self.all_inputs = self.all_inputs[rand_idxs, ...]\n",
    "        if ys is not None:\n",
    "            self.all_labels = ys if not one_hot else dense_to_one_hot(ys)\n",
    "            self.all_labels = self.all_labels[rand_idxs, ...]\n",
    "        else:\n",
    "            self.all_labels = None\n",
    "\n",
    "        # Get splits\n",
    "        self.train_idxs = idxs[:round(split[0] * n_idxs)]\n",
    "        self.valid_idxs = idxs[len(self.train_idxs):\n",
    "                               len(self.train_idxs) + round(split[1] * n_idxs)]\n",
    "        self.test_idxs = idxs[\n",
    "            (len(self.valid_idxs) + len(self.train_idxs)):\n",
    "            (len(self.valid_idxs) + len(self.train_idxs)) +\n",
    "             round(split[2] * n_idxs)]\n",
    "\n",
    "    @property\n",
    "    def X(self):\n",
    "        \"\"\"Inputs/Xs/Images.\n",
    "        Returns\n",
    "        -------\n",
    "        all_inputs : np.ndarray\n",
    "            Original Inputs/Xs.\n",
    "        \"\"\"\n",
    "        return self.all_inputs\n",
    "\n",
    "    @property\n",
    "    def Y(self):\n",
    "        \"\"\"Outputs/ys/Labels.\n",
    "        Returns\n",
    "        -------\n",
    "        all_labels : np.ndarray\n",
    "            Original Outputs/ys.\n",
    "        \"\"\"\n",
    "        return self.all_labels\n",
    "\n",
    "    @property\n",
    "    def train(self):\n",
    "        \"\"\"Train split.\n",
    "        Returns\n",
    "        -------\n",
    "        split : DatasetSplit\n",
    "            Split of the train dataset.\n",
    "        \"\"\"\n",
    "        if len(self.train_idxs):\n",
    "            inputs = self.all_inputs[self.train_idxs, ...]\n",
    "            if self.all_labels is not None:\n",
    "                labels = self.all_labels[self.train_idxs, ...]\n",
    "            else:\n",
    "                labels = None\n",
    "        else:\n",
    "            inputs, labels = [], []\n",
    "        return DatasetSplit(inputs, labels)\n",
    "\n",
    "    @property\n",
    "    def valid(self):\n",
    "        \"\"\"Validation split.\n",
    "        Returns\n",
    "        -------\n",
    "        split : DatasetSplit\n",
    "            Split of the validation dataset.\n",
    "        \"\"\"\n",
    "        if len(self.valid_idxs):\n",
    "            inputs = self.all_inputs[self.valid_idxs, ...]\n",
    "            if self.all_labels is not None:\n",
    "                labels = self.all_labels[self.valid_idxs, ...]\n",
    "            else:\n",
    "                labels = None\n",
    "        else:\n",
    "            inputs, labels = [], []\n",
    "        return DatasetSplit(inputs, labels)\n",
    "\n",
    "    @property\n",
    "    def test(self):\n",
    "        \"\"\"Test split.\n",
    "        Returns\n",
    "        -------\n",
    "        split : DatasetSplit\n",
    "            Split of the test dataset.\n",
    "        \"\"\"\n",
    "        if len(self.test_idxs):\n",
    "            inputs = self.all_inputs[self.test_idxs, ...]\n",
    "            if self.all_labels is not None:\n",
    "                labels = self.all_labels[self.test_idxs, ...]\n",
    "            else:\n",
    "                labels = None\n",
    "        else:\n",
    "            inputs, labels = [], []\n",
    "        return DatasetSplit(inputs, labels)\n",
    "\n",
    "    def mean(self):\n",
    "        \"\"\"Mean of the inputs/Xs.\n",
    "        Returns\n",
    "        -------\n",
    "        mean : np.ndarray\n",
    "            Calculates mean across 0th (batch) dimension.\n",
    "        \"\"\"\n",
    "        return np.mean(self.all_inputs, axis=0)\n",
    "\n",
    "    def std(self):\n",
    "        \"\"\"Standard deviation of the inputs/Xs.\n",
    "        Returns\n",
    "        -------\n",
    "        std : np.ndarray\n",
    "            Calculates std across 0th (batch) dimension.\n",
    "        \"\"\"\n",
    "        return np.std(self.all_inputs, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "[1] os https://docs.python.org/3/library/os.html\n",
    "\n",
    "[2] pickle https://docs.python.org/3/library/pickle.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
